---
title: "R Notebook"
output: html_notebook
---

`gpuR` works straight out of the bat!


```{r}
library(gpuR)
for(i in seq(1:2)) {
    ORDER = 256*(2^i)
     A = matrix(rnorm(ORDER^2), nrow=ORDER)
     B = matrix(rnorm(ORDER^2), nrow=ORDER)
     gpuA = gpuMatrix(A, type="double")
     gpuB = gpuMatrix(B, type="double")
     cputime = system.time({gpuC = gpuA %*% gpuB})[3]
 }
```



# 3.3 PERFORMANCE ANALYSIS ON M40 FOR SINGLE PRECISION
Single precision is quite important for data scientists but openBLAS, nvblas, and gputools use default double-precision (DP) calculation mode of R. So, it will lack competition in some hardware such as Tesla M40 where the DP performance is only 0.2T. In this parts, we will show you how to leverage SP performance in R by gmatrix and gpuR. In the blow testing, we take openBLAS performance results as the baseline.

*R code of gmatrix and gpuR with SP calculation mode
```{r}
library(gpuR)

for(i in seq(1:3)) {
    ORDER = 256*(2^i)
    A = matrix(rnorm(ORDER^2), nrow=ORDER)
    B = matrix(rnorm(ORDER^2), nrow=ORDER)
    gpuA = gpuMatrix(A, type="float")
    gpuB = gpuMatrix(B, type="float")
    cputime = system.time({gpuC = gpuA %*% gpuB})[3]
}
cputime
```

```{r}
# modified
library(gpuR)

for(i in seq(1:5)) {
    ORDER = 64*(2^i)
    A = matrix(rnorm(ORDER^2), nrow=ORDER)
    B = matrix(rnorm(ORDER^2), nrow=ORDER)
    gpuA = gpuMatrix(A, type="float")
    gpuB = gpuMatrix(B, type="float")
    cputime = system.time({gpuC = gpuA %*% gpuB})[3]
}
cputime
```
